{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV7LRnYBh_aV"
      },
      "outputs": [],
      "source": [
        "!pip install pandas requests\n",
        "import requests\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "GITHUB_TOKEN = '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'\n",
        "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
        "GITHUB_API_URL = \"https://api.github.com\"\n",
        "LOCATION = \"Toronto\"\n",
        "\n",
        "def fetch_users(location, min_followers):\n",
        "    url = f\"{GITHUB_API_URL}/search/users\"\n",
        "    params = {\n",
        "        'q': f'location:{location} followers:>{min_followers}',\n",
        "        'per_page': 100,\n",
        "        'page': 1\n",
        "    }\n",
        "    users = []\n",
        "    while True:\n",
        "        response = requests.get(url, params=params)\n",
        "        # Check for rate limiting\n",
        "        if response.status_code == 403:\n",
        "            print(\"Rate limit hit. Waiting for 5 minutes...\")\n",
        "            time.sleep(300)  # Wait for 5 minutes\n",
        "            continue  # Retry the request\n",
        "        data = response.json()\n",
        "        users.extend(data.get('items', []))\n",
        "        if 'Link' in response.headers and 'rel=\"next\"' in response.headers['Link']:\n",
        "            params['page'] += 1\n",
        "        else:\n",
        "            break\n",
        "    return users\n",
        "\n",
        "# Function to fetch user details\n",
        "def fetch_user_details(user_url):\n",
        "    response = requests.get(user_url)\n",
        "    # Check for rate limiting\n",
        "    if response.status_code == 403:\n",
        "        print(\"Rate limit hit. Waiting for 5 minutes...\")\n",
        "        time.sleep(300)  # Wait for 5 minutes\n",
        "        return fetch_user_details(user_url)  # Retry the request\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "# Fetch users and their details\n",
        "users = fetch_users(LOCATION, MIN_FOLLOWERS)\n",
        "cleaned_users = []\n",
        "for user in users:\n",
        "    details = fetch_user_details(user['url'])\n",
        "    cleaned_users.append({\n",
        "        'login': details['login'],\n",
        "        'name': details['name'],\n",
        "        'company': details['company'].strip('@ ').upper() if details['company'] else None,\n",
        "        'location': details['location'],\n",
        "        'email': details['email'],\n",
        "        'hireable': details['hireable'],\n",
        "        'bio': details['bio'],\n",
        "        'public_repos': details['public_repos'],\n",
        "        'followers': details['followers'],\n",
        "        'following': details['following'],\n",
        "        'created_at': details['created_at'],\n",
        "    })\n",
        "\n",
        "# Save to CSV\n",
        "users_df = pd.DataFrame(cleaned_users)\n",
        "users_df.to_csv('/content/drive/My Drive/users.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas requests\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Setting GitHub personal access token\n",
        "GITHUB_TOKEN = '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'\n",
        "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
        "\n",
        "# Load the users.csv file into a pandas DataFrame\n",
        "users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n",
        "\n",
        "all_repo_details = []\n",
        "\n",
        "def fetch_repo_details(user_login):\n",
        "    repo_details_for_user = []\n",
        "    repos_url = f\"https://api.github.com/users/{user_login}/repos?sort=pushed&per_page=100\"\n",
        "\n",
        "    for page in range(1, 6):\n",
        "        response = requests.get(repos_url + f\"&page={page}\", headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            repo_details = response.json()\n",
        "            if not repo_details:  # Break if no more repos on this page\n",
        "                break\n",
        "            for repo in repo_details:\n",
        "                license_name = repo.get('license', {}).get('name') if repo.get('license') is not None else None\n",
        "                repo_details_for_user.append({\n",
        "                    \"login\": user_login,\n",
        "                    \"full_name\": repo.get('full_name'),\n",
        "                    \"created_at\": repo.get('created_at'),\n",
        "                    \"stargazers_count\": repo.get('stargazers_count'),\n",
        "                    \"watchers_count\": repo.get('watchers_count'),\n",
        "                    \"language\": repo.get('language'),\n",
        "                    \"has_projects\": repo.get('has_projects'),\n",
        "                    \"has_wiki\": repo.get('has_wiki'),\n",
        "                    \"license_name\": license_name\n",
        "                })\n",
        "        else:\n",
        "            print(f\"Error fetching repository details for user: {user_login}, Status Code: {response.status_code}\")\n",
        "            break\n",
        "    return repo_details_for_user\n",
        "\n",
        "\n",
        "# Use ThreadPoolExecutor for parallel processing\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:  # Adjust max_workers as needed\n",
        "    results = list(executor.map(fetch_repo_details, users_df['login']))\n",
        "\n",
        "# Flatten the results list\n",
        "for result in results:\n",
        "    all_repo_details.extend(result)\n",
        "\n",
        "\n",
        "# Create a new DataFrame and save to CSV\n",
        "repo_details_df = pd.DataFrame(all_repo_details)\n",
        "repo_details_df.to_csv('/content/drive/My Drive/repositories.csv', index=False)\n",
        "print(\"Repository data saved to repositories.csv\")"
      ],
      "metadata": {
        "id": "jTisM6D5jDsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}