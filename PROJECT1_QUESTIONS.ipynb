{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ru1ymPcDsSlrFFmco5QLmtEdFkJYMdqt","timestamp":1730299800949}],"authorship_tag":"ABX9TyPpb8T58myjQiIClx4h7frA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["##Q1:\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# Load the users.csv file into a pandas DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Filter users located in Toronto\n","\n","\n","# Sort by followers in descending order and select the top 5\n","top_5_users = users_df.sort_values(by=['followers'], ascending=False).head(5)\n","\n","# Get the logins of the top 5 users\n","top_5_logins = top_5_users['login'].tolist()\n","\n","# Print the logins as a comma-separated string\n","print(','.join(top_5_logins))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iSPZgR97GKF","executionInfo":{"status":"ok","timestamp":1730271472967,"user_tz":-330,"elapsed":4228,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"bcf247c5-070f-4c09-b4c1-74e49848a32f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","aneagoie,ZhangMYihua,susanli2016,thedaviddias,ange-yaghi\n"]}]},{"cell_type":"code","source":["##Q2"],"metadata":{"id":"s3Ii7PQ_N4XJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# List of locations to consider\n","#LOCATIONS = [\"Toronto, Canada\", \"Toronto, ON\", \"Toronto, ON, Canada\", \"Toronto\", \"Toronto (GTA), Canada + Available for Remote\"]\n","\n","# Load the users.csv file into a pandas DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Filter users located in Toronto (using any of the location variations)\n","toronto_users = users_df\n","\n","# Convert 'created_at' to datetime objects for proper sorting\n","toronto_users['created_at'] = pd.to_datetime(toronto_users['created_at'])\n","\n","# Sort by 'created_at' in ascending order and select the top 5\n","earliest_5_users = toronto_users.sort_values(by=['created_at']).head(5)\n","\n","# Get the logins of the earliest 5 users\n","earliest_5_logins = earliest_5_users['login'].tolist()\n","\n","# Print the logins as a comma-separated string\n","print(','.join(earliest_5_logins))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7AMA51uNtda","executionInfo":{"status":"ok","timestamp":1730271620388,"user_tz":-330,"elapsed":494,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"a5cce18b-881c-467d-b722-47b1abae4938"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["jamesmacaulay,michaelklishin,myles,nwjsmith,vito\n"]}]},{"cell_type":"code","source":["##Q3:\n","import pandas as pd\n","\n","# Load the repositories.csv file into a pandas DataFrame\n","repos_df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Filter out rows with missing license_name\n","repos_with_license = repos_df.dropna(subset=['license_name'])\n","\n","# Get the top 3 most frequent license names\n","top_3_licenses = repos_with_license['license_name'].value_counts().head(3).index.tolist()\n","\n","# Print the license names as a comma-separated string\n","print(','.join(top_3_licenses))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbgQAkBwOo_6","executionInfo":{"status":"ok","timestamp":1730271707809,"user_tz":-330,"elapsed":1053,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"968b468d-03d6-49ab-830b-1c33023777bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mit,other,apache-2.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"65e4NhJF3z0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Q4:\n","import pandas as pd\n","\n","# Load the users.csv file into a pandas DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Get the most frequent company\n","most_frequent_company = users_df['company'].mode()[0]\n","\n","# Print the most frequent company\n","print(most_frequent_company)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMw8JttAbirR","executionInfo":{"status":"ok","timestamp":1730275087534,"user_tz":-330,"elapsed":417,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"1ed19790-84e0-4b0b-f287-4addda571404"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["UNIVERSITY OF TORONTO\n"]}]},{"cell_type":"code","source":["##Q5:\n","repos_df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Filter out rows with missing language\n","repos_with_language = repos_df.dropna(subset=['language'])\n","\n","# Get the most frequent language\n","most_frequent_language = repos_with_language['language'].mode()[0]\n","\n","# Print the most frequent language\n","print(most_frequent_language)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBkaToX-b16F","executionInfo":{"status":"ok","timestamp":1730275155823,"user_tz":-330,"elapsed":434,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"eab929b1-4d70-48c6-8f32-3cbc61b533e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["JavaScript\n"]}]},{"cell_type":"code","source":["##Q6:\n","import pandas as pd\n","\n","# Load the users.csv and repositories.csv files into pandas DataFrames\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","repos_df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Convert 'created_at' to datetime objects in users_df\n","users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n","\n","# Filter users who joined after 2020\n","users_after_2020 = users_df[users_df['created_at'].dt.year > 2020]\n","\n","# Merge the DataFrames to link users and repositories\n","merged_df = pd.merge(users_after_2020, repos_df, on='login', how='inner')\n","\n","# Filter out rows with missing language\n","repos_with_language = merged_df.dropna(subset=['language'])\n","\n","# Get the second most frequent language\n","second_most_frequent_language = repos_with_language['language'].value_counts().index[1]\n","\n","# Print the second most frequent language\n","print(second_most_frequent_language)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K27028efcDSd","executionInfo":{"status":"ok","timestamp":1730275215019,"user_tz":-330,"elapsed":594,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"f6eecc65-39bd-4379-8cde-af66e4fcbffc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TypeScript\n"]}]},{"cell_type":"code","source":["##Q7:\n","import pandas as pd\n","\n","# Load the repositories.csv file into a pandas DataFrame\n","repos_df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Filter out rows with missing language\n","repos_with_language = repos_df.dropna(subset=['language'])\n","\n","# Group by language and calculate the average stars per repository\n","language_avg_stars = repos_with_language.groupby('language')['stargazers_count'].mean()\n","\n","# Find the language with the highest average stars\n","highest_avg_stars_language = language_avg_stars.idxmax()\n","\n","# Print the language with the highest average stars\n","print(highest_avg_stars_language)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gqLwJe0dI-b","executionInfo":{"status":"ok","timestamp":1730275496541,"user_tz":-330,"elapsed":551,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"df687add-f9b2-4a7c-c8eb-5f5dcf8b1a42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cython\n"]}]},{"cell_type":"code","source":["##Q8:\n","import pandas as pd\n","\n","# Load the users data\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Calculate leader_strength\n","users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n","\n","# Sort by leader_strength in descending order and get the top 5\n","top_5_leader_strength = users_df.sort_values(by=['leader_strength'], ascending=False).head(5)\n","\n","# Extract the logins of the top 5 users\n","top_5_logins = top_5_leader_strength['login'].tolist()\n","\n","# Print the logins as a comma-separated string\n","print(','.join(top_5_logins))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VA1nA9SidrqK","executionInfo":{"status":"ok","timestamp":1730275633941,"user_tz":-330,"elapsed":554,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"22341b52-33fb-4e7c-f908-b9b52df8e77b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["aneagoie,nayuki,GrapheneOS,hlissner,rspivak\n"]}]},{"cell_type":"code","source":["##Q9: ans:0.056\n","import pandas as pd\n","\n","# Load the users data\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","print(len(users_df))\n","# Filter users located in Toronto\n","#toronto_users = users_df[users_df['location'] == 'Toronto']\n","#print(len(toronto_users ))\n","toronto_users = users_df\n","# Calculate the correlation between followers and public_repos\n","correlation = toronto_users['followers'].corr(toronto_users['public_repos'])\n","\n","# Print the correlation rounded to 3 decimal places\n","print(f'{correlation:.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oIFA_SQd4_y","executionInfo":{"status":"ok","timestamp":1730276063892,"user_tz":-330,"elapsed":532,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"af9cf9eb-a724-482f-ff35-d50dcfba85d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["685\n","0.055\n"]}]},{"cell_type":"code","source":["##Q10:\n","import pandas as pd\n","import statsmodels.api as sm\n","\n","# Load the CSV file\n","df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Filter for users in Toronto\n","#toronto_users = df[df['location'].str.contains('Toronto', na=False)]\n","toronto_users = df\n","# Define the independent variable (public repositories) and dependent variable (followers)\n","X = toronto_users['public_repos']\n","y = toronto_users['followers']\n","\n","# Add a constant to the independent variable\n","X = sm.add_constant(X)\n","\n","# Fit the regression model\n","model = sm.OLS(y, X).fit()\n","\n","# Get the slope (coefficient for public_repos)\n","slope = model.params['public_repos']\n","\n","# Print the slope rounded to 3 decimal places\n","print(f\"{slope:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JVx_S7bf-yX","executionInfo":{"status":"ok","timestamp":1730276376853,"user_tz":-330,"elapsed":531,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"7a3bee5d-0902-4b9d-d7c2-ef1cb6748d66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.253\n"]}]},{"cell_type":"code","source":["##Q11:  Ans:NaN\n","import pandas as pd\n","\n","# Load the CSV file\n","df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Convert boolean columns to integers (1 for True, 0 for False)\n","df['has_projects'] = df['has_projects'].astype(int)\n","df['has_wiki'] = df['has_wiki'].astype(int)\n","\n","# Calculate the correlation\n","correlation = df['has_projects'].corr(df['has_wiki'])\n","\n","# Print the correlation rounded to 3 decimal places\n","print(f\"{correlation:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rThYuL2agtcn","executionInfo":{"status":"ok","timestamp":1730276430280,"user_tz":-330,"elapsed":528,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"95e6742a-260e-4e3e-d30f-ed6cbf1184f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.395\n"]}]},{"cell_type":"code","source":["##Q12:Ans:NaN"],"metadata":{"id":"VyEqFh0bhFI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# Load the users DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Calculate the average following for hireable users\n","#users_df['hireable'] = users_df['hireable'].astype(int)\n","\n","hireable_avg_following = users_df[users_df['hireable'] == True]['following'].mean()\n","print(len(users_df['hireable']!=True))\n","print(\"hire:\",hireable_avg_following)\n","\n","# Calculate the average following for non-hireable users\n","non_hireable_avg_following = users_df[users_df['hireable'] !=True]['following'].mean()\n","print(\"non\",non_hireable_avg_following)\n","# Calculate the difference\n","diff = hireable_avg_following - non_hireable_avg_following\n","\n","# Print the result formatted to 3 decimal places\n","print(f\"{diff:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2kYXDDHhZnt","executionInfo":{"status":"ok","timestamp":1730276611151,"user_tz":-330,"elapsed":4267,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"000f91d5-bdc2-4abf-9edb-97ac83373205"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","685\n","hire: 112.91964285714286\n","non 126.22559652928416\n","-13.306\n"]}]},{"cell_type":"code","source":["\n","\n"],"metadata":{"id":"Josv4X-9hqeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Q14:\n","import pandas as pd\n","\n","# Load the repositories DataFrame\n","repos_df = pd.read_csv('/content/drive/My Drive/repositories.csv')\n","\n","# Convert 'created_at' to datetime objects with UTC timezone\n","repos_df['created_at'] = pd.to_datetime(repos_df['created_at'], utc=True)\n","\n","# Filter for repositories created on weekends (Saturday or Sunday)\n","weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek.isin([5, 6])]\n","\n","# Group by 'login' and count repositories created on weekends\n","repo_counts = weekend_repos.groupby('login')['full_name'].count()\n","\n","# Get the top 5 users\n","top_5_users = repo_counts.nlargest(5).index.tolist()\n","\n","# Print the result as a comma-separated string\n","print(','.join(top_5_users))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rG5rWHlkmDh","executionInfo":{"status":"ok","timestamp":1730277450529,"user_tz":-330,"elapsed":624,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"5316f3c7-267b-4f72-b450-56b802e4b365"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ldct,DjDeveloperr,davepagurek,rajansagarwal,andyw8\n"]}]},{"cell_type":"code","source":["##Q15:Ans:NaN\n","import pandas as pd\n","\n","# Load the users DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Calculate fraction of hireable users with email\n","hireable_email_fraction = users_df[users_df['hireable'] == True]['email'].notna().mean()\n","\n","# Calculate fraction of non-hireable users with email\n","non_hireable_email_fraction = users_df[users_df['hireable'] != True]['email'].notna().mean()\n","\n","\n","# Calculate the difference and round to 3 decimal places\n","difference = round(hireable_email_fraction - non_hireable_email_fraction, 3)\n","\n","# Print the result\n","print(difference)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKOnZO6HkxFa","executionInfo":{"status":"ok","timestamp":1730277494307,"user_tz":-330,"elapsed":491,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"a20e1dc7-4a35-46d8-9417-aa7d7e82bac2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.135\n"]}]},{"cell_type":"code","source":["##Q16:\n"],"metadata":{"id":"vU9nzidjk8RJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the users DataFrame\n","users_df = pd.read_csv('/content/drive/My Drive/users.csv')\n","\n","# Filter out users with missing names\n","users_with_names = users_df[users_df['name'].notna()]\n","\n","# Extract surnames and count occurrences\n","surname_counts = users_with_names['name'].str.strip().str.split().str[-1].value_counts()\n","print(surname_counts)\n","\n","# Get the most common surname(s) and their count\n","max_count = surname_counts.max()\n","most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n","most_common_surnames.sort()  # Sort alphabetically\n","\n","# Print the results\n","print(','.join(most_common_surnames))\n","print(max_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXij3a6DlEWY","executionInfo":{"status":"ok","timestamp":1730277568356,"user_tz":-330,"elapsed":11,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"a9d9724e-6870-414f-a85a-700dd4df5115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name\n","Ahmed       4\n","Kumar       3\n","Smith       3\n","Li          3\n","Wu          3\n","           ..\n","Santos      1\n","Peiris      1\n","Teneycke    1\n","Hura        1\n","D'Amelio    1\n","Name: count, Length: 630, dtype: int64\n","Ahmed\n","4\n"]}]},{"cell_type":"code","source":["##Q13:\n"],"metadata":{"id":"PmSZ6gFQlP2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gpWY5A3Ull8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y1EHY3F3nXPH"},"execution_count":null,"outputs":[]},{"source":["##Q13:\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# Load the data\n","users_df = pd.read_csv('/content/drive/My Drive/users123.csv')  # Replace 'users123.csv' if needed\n","\n","# Assuming 'bio' column contains the bios and 'followers' column contains the follower count\n","# Filter out users without bios\n","users_df['bio1'] = users_df['bio'].astype(str).str.replace('nan', '')  # Replace 'nan' strings with empty strings\n","users_with_bios = users_df[users_df['bio1'] != ''].copy()  # Filter out users with empty bios and create a copy\n","\n","# Calculate bio word count using .loc\n","users_with_bios.loc[:, 'bio_word_count'] = users_with_bios['bio1'].str.split().str.len()\n","\n","# Prepare data for regression\n","X = users_with_bios[['bio_word_count']]  # Independent variable: Bio word count\n","y = users_with_bios['followers']  # Dependent variable: Followers\n","\n","# Create and fit the linear regression model\n","model = LinearRegression()\n","model.fit(X, y)\n","\n","# Get the coefficient (slope)\n","coefficient = model.coef_[0]\n","\n","# Print the regression slope\n","print(f\"Regression slope of followers on bio word count: {coefficient:.3f}\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqjzNMZMnYEd","executionInfo":{"status":"ok","timestamp":1730278169152,"user_tz":-330,"elapsed":4154,"user":{"displayName":"JAI SUBIKSHA T","userId":"15082078074410074725"}},"outputId":"dfe44959-e3bc-440b-f4b8-f340340fbc40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Regression slope of followers on bio word count: 8.398\n"]}]}]}